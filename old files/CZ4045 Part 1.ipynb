{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Sequence Tagging: NER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1 Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1.1 Download Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\woony\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Collecting gensim\n",
      "  Obtaining dependency information for gensim from https://files.pythonhosted.org/packages/ab/b0/d58dc405fd60ab546ca714321235dc2d455b2dc06bfb4fc1092940c749fc/gensim-4.3.2-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached gensim-4.3.2-cp310-cp310-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\woony\\anaconda3\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\woony\\anaconda3\\lib\\site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\woony\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Using cached gensim-4.3.2-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.0\n",
      "    Uninstalling gensim-4.3.0:\n",
      "      Successfully uninstalled gensim-4.3.0\n",
      "Successfully installed gensim-4.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1.2 Download the pretrained word2vec embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Download the embeddings \"word2vec-google-news-300\"\n",
    "w2v = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 1.1\n",
    "###### Based on word2vec embeddings you have downloaded, use cosine similarity to find the most similar word to each of these words: (a) “student”; (b) “Apple”; (c) “apple”. Report the most similar word and its cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_and_cosine_similarity(word:list, top_n:int):\n",
    "    result = {}\n",
    "    for w in word:\n",
    "        similarities = w2v.cosine_similarities(w2v[w], w2v.vectors)\n",
    "        sorted_similarities = sorted(similarities[:], reverse=True)[:top_n+1]\n",
    "        result[w] = [(w2v.index_to_key[np.where(similarities == s)[0][0]], s) for s in sorted_similarities if w2v.index_to_key[np.where(similarities == s)[0][0]]!=w]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar word and its cosine similarity by using .most_similar(): \n",
      "student\t [('students', 0.7294867038726807)]\n",
      "Apple\t [('Apple_AAPL', 0.7456986308097839)]\n",
      "apple\t [('apples', 0.720359742641449)]\n",
      "\n",
      "Most similar word and its cosine similarity by using .cosine_similarities(): \n",
      "student\t [('students', 0.7294867)]\n",
      "Apple\t [('Apple_AAPL', 0.74569863)]\n",
      "apple\t [('apples', 0.72035974)]\n"
     ]
    }
   ],
   "source": [
    "word_list = [\"student\", \"Apple\", \"apple\"]\n",
    "print(\"Most similar word and its cosine similarity by using .most_similar(): \")\n",
    "for word in word_list:\n",
    "    print(word+'\\t', w2v.most_similar(word,topn=1))\n",
    "\n",
    "print(\"\\nMost similar word and its cosine similarity by using .cosine_similarities(): \")\n",
    "r = get_word_and_cosine_similarity(word_list, 1)\n",
    "for k,v in r.items():\n",
    "    print(k+'\\t', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2 Data\n",
    "###### Then you can start to prepare the dataset. For NER, you will work with [CoNLL2003](https://github.com/TheAnig/NER-LSTM-CNN-Pytorch/tree/master/data) (click and download “eng.testa”, “eng.testb”, “eng.train”). Before training, you need to preprocess the dataset such that each of them contains a training file, a development file and a test file. The development file is used to select the best model during training. The test file is used for final evaluation. For CoNLL2003, the training, development and test file corresponds to “eng.train”, “eng.testa” and “eng.testb”, respectively. Note that you only need to use the first and the last column of each line corresponding to the input word and the word label, respectively. A screenshot of the data is shown in Figure 1. In this example, there are two sentences (separated by ‘\\n’). The input for each sentence is composed of the words from the first column. For example, the first sentence in Figure 1 corresponds to “CRICKET - LEICESTERSHIRE TAKE OVER AT TOP AFTER INNINGS VICTORY.” The label for each of the first 3 words CRICKET, -, LERCESTERSHIRE corresponds to ‘O’, ‘O’, ‘I-ORG’, respectively"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "train_file = \"eng.train\"\n",
    "verification_file = \"eng.testa\"\n",
    "test_file = \"eng.testb\"\n",
    "\n",
    "# Function to read and process a CoNLL2003 file and returns df\n",
    "def process_files(file_path, csv_name):\n",
    "    \"\"\" Parameters:\n",
    "        - file_path: CoNLL2003 files\n",
    "        - csv_name: Bool\n",
    "             returns pd file, columns: [\"Sentence Number\", \"Word\", \"NEr tag\"]\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    sentence_no = 1\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for row in file:\n",
    "            line = row.strip()\n",
    "            if not line:  # Empty line indicates end of a sentence\n",
    "                sentence_no += 1\n",
    "            else:\n",
    "                ner = line.split(\" \")\n",
    "                # ensuring that for each data there is a word and the word's NER label\n",
    "                assert all([ner[i] for i in range(4)])\n",
    "                data.append([sentence_no, ner[0], ner[3]])\n",
    "    \n",
    "    with open(csv_name, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Sentence Number\", \"Word\", \"NEr tag\"])\n",
    "        for word in data:\n",
    "            writer.writerow([word[0], word[1], word[2]])\n",
    "    return pd.read_csv(csv_name)\n",
    "\n",
    "# Function to load existing csv file if have\n",
    "def load_files(file_name):\n",
    "    return pd.read_csv(file_name)\n",
    "\n",
    "# Process the data files\n",
    "train_df = process_files(train_file, csv_name=\"train_data.csv\")\n",
    "validation_df = process_files(verification_file, csv_name=\"verification_data.csv\")\n",
    "test_df = process_files(test_file, csv_name=\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2\n",
    "###### (a) Describe the size (number of sentences) of the training, development and test file for CoNLL2003. Specify the complete set of all possible word labels based on the tagging scheme (IO, BIO, etc.) you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training data information\n",
      "> Number of sentences:    14987\n",
      "> Count of Unique words:  23623\n",
      "> Type of tags:           ['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n",
      "\n",
      "====================================================================================================\n",
      "Verification data information\n",
      "> Number of sentences:    3466\n",
      "> Count of Unique words:  9966\n",
      "> Type of tags:           ['B-MISC', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n",
      "\n",
      "====================================================================================================\n",
      "Test data information\n",
      "> Number of sentences:    3684\n",
      "> Count of Unique words:  9489\n",
      "> Type of tags:           ['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "With the given shapes, parameters and type of tags exists, we select the tagging scheme to be BIO as it has B,I,O tags.\n"
     ]
    }
   ],
   "source": [
    "file_labels = [\"Training\", \"Verification\", \"Test\"]\n",
    "for i, df in enumerate([train_df, validation_df, test_df]):\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{file_labels[i]} data information\")\n",
    "    print(f\"> Number of sentences:    {df['Sentence Number'].max()}\")\n",
    "    print(f\"> Count of Unique words:  {len(df['Word'].unique())}\")\n",
    "    print(f\"> Type of tags:           {sorted(df['NEr tag'].unique())}\\n\")\n",
    "print(\"=\"*100,'\\n')\n",
    "\n",
    "print(\"With the given shapes, parameters and type of tags exists, we select the tagging scheme to be BIO as it has B,I,O tags.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (b) Choose an example sentence from the training set of CoNLL2003 that has at least two named entities with more than one word. Explain how to form complete named entities from the label for each word, and list all the named entities in this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q1_2_b(dataset, min_sentence_len=10, random_seed=1):\n",
    "    s,w,t = np.inf,[],[]\n",
    "    sentences = {}\n",
    "    tags = {}\n",
    "    for index, row in dataset.iterrows():\n",
    "        if s!=row[\"Sentence Number\"]: # new sentence detected\n",
    "            sentences[s] = w\n",
    "            tags[s] = t\n",
    "            s,w,t = row[\"Sentence Number\"], [], []\n",
    "        w.append(row[\"Word\"])\n",
    "        t.append(row[\"NEr tag\"])\n",
    "    \n",
    "    x = [i for i in range(len(sentences))]\n",
    "    random.Random(random_seed).shuffle(x)\n",
    "    for idx in x:\n",
    "    # Check existing for at least two consequtive named entities with more than one word using sliding window\n",
    "        if len(sentences[idx]) >= min_sentence_len:\n",
    "            for i in range(1, len(tags[idx])):\n",
    "                if tags[idx][i-1]!='O' and tags[idx][i]!='O': # Check if both is not 'O' tag\n",
    "                    if tags[idx][i-1].split(\"-\")[1] == tags[idx][i].split(\"-\")[1]: # Check if both NE tags are the same type e.g. LOC/MISC/ORG/PER\n",
    "                        return idx, sentences[idx], tags[idx]\n",
    "    return None, None\n",
    "\n",
    "def get_ne(sentence, tag):\n",
    "    phrases = {}\n",
    "    temp_phrase = []\n",
    "    first_tag = ''\n",
    "    for i in range(1, len(sentence)):\n",
    "        if tag[i] != 'O':\n",
    "            if not first_tag: \n",
    "                first_tag = tag[i].split('-')[1]\n",
    "            if first_tag == tag[i].split('-')[1]: \n",
    "                temp_phrase.append(sentence[i])\n",
    "        else:\n",
    "            if temp_phrase:\n",
    "                phrases[' '.join(temp_phrase)] = first_tag\n",
    "                temp_phrase = []\n",
    "            else:\n",
    "                temp_phrase = []\n",
    "                first_tag = ''\n",
    "    return phrases\n",
    "\n",
    "sentence_no, sentence, tags = get_q1_2_b(train_df, min_sentence_len=10, random_seed=1)\n",
    "name_entities = get_ne(sentence, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      "> Outright gas oil prices were notionally softer as the NYMEX heating oil contract headed lower , and following news that the Indian Oil Corp ( IOC ) had issued a tender to buy only 120,000 tonnes of high speed diesel for October .\n",
      "\n",
      "Original tag:\n",
      "> O O O O O O O O O O O O O O O O O O O O O I-ORG I-ORG I-ORG O I-ORG O O O O O O O O O O O O O O O O O\n",
      "\n",
      "Tagged sentence selected:\n",
      "> Outright/O gas/O oil/O prices/O were/O notionally/O softer/O as/O the/O NYMEX/O heating/O oil/O contract/O headed/O lower/O ,/O and/O following/O news/O that/O the/O Indian/I-ORG Oil/I-ORG Corp/I-ORG (/O IOC/I-ORG )/O had/O issued/O a/O tender/O to/O buy/O only/O 120,000/O tonnes/O of/O high/O speed/O diesel/O for/O October/O ./O\n",
      "\n",
      "Name entities found: \n",
      "> ORG: Indian Oil Corp\n",
      "> ORG: IOC\n",
      "\n",
      "To form complete named entities from the label for each word, we need to consider firstly that the tags are provided/able to be retrieved by corpus/gazetteer. For each single/consequtive Name Entities(ER) recognition tags, it is the complete phrase of the name entity. The type of the entity can be known by the tag itself, if in this example, ORG was tagged and hence we know the word/phrase is an Organization. However, the data provided does not fully follow the BIO tagging scheme entirely, with the start of the NE phrase not tagged with a \"B\", and since when we are using the \"BIO\" tagging scheme there is no Stop/Ending tags, hence the only way we can segregate phrases is by using the \"O\"-outside \"BIO\" tag. \n"
     ]
    }
   ],
   "source": [
    "print(f\"Original sentence:\\n> {' '.join(sentence)}\\n\")\n",
    "print(f\"Original tag:\\n> {' '.join(tags)}\\n\")\n",
    "print(f\"Tagged sentence selected:\\n> {' '.join([sentence[i]+'/'+ tags[i] for i in range(len(sentence))])}\\n\")\n",
    "\n",
    "print(\"Name entities found: \")\n",
    "for k,v in name_entities.items():\n",
    "    print(f\"> {v}: {k}\")\n",
    "\n",
    "print('\\nTo form complete named entities from the label for each word, we need to consider firstly that the tags are provided/able to be retrieved by corpus/gazetteer. For each single/consequtive Name Entities(ER) recognition tags, it is the complete phrase of the name entity. The type of the entity can be known by the tag itself, if in this example, ORG was tagged and hence we know the word/phrase is an Organization. However, the data provided does not fully follow the BIO tagging scheme entirely, with the start of the NE phrase not tagged with a \"B\", and since when we are using the \"BIO\" tagging scheme there is no Stop/Ending tags, hence the only way we can segregate phrases is by using the \"O\"-outside \"BIO\" tag. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.3 Model\n",
    "###### Now with the pretrained word embeddings acquired from Section 1.1, and the CoNLL2003 dataset acquired from Section 1.2, you need to train an NER model using the training set, conforming to these requirements:\n",
    "• Use the pretrained word embeddings from Section 1.1 as inputs; do not update them during training (they are “frozen”).\n",
    "\n",
    "• Design a neural network transforming the input for each word to its final vector representation, which will be fed into the softmax classifier to predict the final label for each word. The neural network could be a simple linear layer, a feedforward network (a linear transformation plus a nonlinear activation function), or a recurrent neural network (RNN/LSTM). You are encouraged to use more effective networks (e.g., LSTM) because the performance of the model will be taken into consideration when graded.\n",
    "\n",
    "• Use the development set to evaluate the performance of the model for each epoch during training. Please use f1 score to measure the performance. For evaluation metric and code, refer to the following link: https://github.com/chakki-works/seqeval/tree/master. (Please make sure your sequence tagging scheme aligns with the provided evaluation code. Otherwise,\n",
    "you may revise the code accordingly.)\n",
    "\n",
    "• Use the mini-batch strategy during training. You may choose any preferred optimizer (e.g., SGD, Adagrad, Adam, RMSprop). Be careful when you choose your initial learning rate and mini-batch size. (You may use the development set to check the performance and decide the optimal configuration.) Train the network until the f1 score on the development set is not increasing. Use the trained network to classify words in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.3\n",
    "###### (a) Discuss how you deal with new words in the training set which are not found in the pretrained dictionary. Likewise, how do you deal with new words in the test set which are not found in either the pretrained dictionary or the training set? Show the corresponding code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the data and convert NER tags to numerical labels\n",
    "def preprocess_data(df, w2v_model, label):\n",
    "    word_embeddings = []\n",
    "    ner_labels = []\n",
    "    for i, row in df.iterrows():\n",
    "        word = row['Word']\n",
    "        ner_tag = row['NEr tag']\n",
    "        if word in w2v_model:\n",
    "            word_vector = w2v_model[word]\n",
    "        else:\n",
    "#             word_vector = np.zeros(300)  # Use zero vectors for out-of-vocabulary words\n",
    "            word_vector = np.zeros((300,))\n",
    "        assert len(word_vector) == 300\n",
    "        word_embeddings.append(word_vector)\n",
    "        onehot = [0]*len(label)\n",
    "        onehot[label.index(ner_tag)] = 1\n",
    "        ner_labels.append(onehot)\n",
    "    return torch.tensor(np.array(word_embeddings), dtype=torch.float64), torch.tensor(np.array(ner_labels), dtype=torch.long)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class NERModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_labels, pretrained_embeddings):\n",
    "        super(NERModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)  # Freeze the embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(2 * hidden_dim, num_labels)  # Multiply by 2 for bidirectional LSTM\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, x):    \n",
    "        x = torch.clamp(x, min=0, max=self.embedding.num_embeddings - 1)\n",
    "        x = x.long()\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        logits = self.linear(lstm_out)\n",
    "        output = self.softmax(logits)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Define hyperparameters\n",
    "ner_labels = ['B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG', 'I-PER', 'O']\n",
    "embedding_dim = 300\n",
    "hidden_dim = 128 # Change to see if there are any improvements\n",
    "num_labels = len(ner_labels)\n",
    "pretrained_embeddings = torch.FloatTensor(w2v.vectors) \n",
    "\n",
    "# Initialize the NER model\n",
    "model = NERModel(embedding_dim, hidden_dim, num_labels, pretrained_embeddings)\n",
    "# # not updating the weights during training\n",
    "# model.embedding.weight.requires_grad = False\n",
    "# Define your loss function and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train, y_train = preprocess_data(train_df, w2v, ner_labels)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "X_validation, y_validation = preprocess_data(validation_df, w2v, ner_labels)\n",
    "validation_dataset = TensorDataset(X_validation, y_validation)\n",
    "validation_data_loader = DataLoader(validation_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                       | 1/10 [21:55<3:17:15, 1315.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 5.6016, Val Loss: 5.5999, Train Accuracy: 6.8121, Test Accuracy: 6.8332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                               | 2/10 [44:02<2:56:18, 1322.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 5.5998, Val Loss: 5.5999, Train Accuracy: 6.8336, Test Accuracy: 6.8332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████                                                      | 3/10 [1:06:08<2:34:26, 1323.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 5.5998, Val Loss: 5.5999, Train Accuracy: 6.8336, Test Accuracy: 6.8332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████▊                                              | 4/10 [1:28:24<2:12:53, 1328.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 5.5998, Val Loss: 5.5999, Train Accuracy: 6.8336, Test Accuracy: 6.8332\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "# Initialize EarlyStopper\n",
    "early_stopper = EarlyStopper(patience=3)\n",
    "\n",
    "# Lists to store train and test accuracies and losses\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "#=======================Training=======================\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for idx, batch in enumerate(train_data_loader):\n",
    "        batch_data, batch_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = loss_fn(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate train accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += batch_labels.size(0)\n",
    "        correct_train += (predicted == batch_labels).sum().item()\n",
    "    \n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss)  # Store train loss\n",
    "    \n",
    "#=======================Testing=======================\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_validation = 0\n",
    "    total_validation = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in validation_data_loader:\n",
    "            outputs = model(batch_data)\n",
    "            loss = loss_fn(outputs, batch_labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calculate test accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_validation += batch_labels.size(0)\n",
    "            correct_validation += (predicted == batch_labels).sum().item()\n",
    "    \n",
    "    test_accuracy = correct_validation / total_validation\n",
    "    validation_accuracies.append(test_accuracy)\n",
    "    validation_losses.append(val_loss)  # Store test loss\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_data_loader)\n",
    "    avg_val_loss = val_loss / len(validation_data_loader)\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if early_stopper.early_stop(avg_val_loss):\n",
    "        print(f\"Early stopping at epoch ({epoch+1}) due to no improvement in validation loss.\")\n",
    "        break\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EarlyStopper\n",
    "early_stopper = EarlyStopper(patience=3)\n",
    "\n",
    "# Training and validation loop\n",
    "epochs = 10\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_data, batch_labels in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = loss_fn(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    average_loss = total_loss / len(train_data_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}] - Training Loss: {average_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in val_data_loader:\n",
    "            outputs = model(batch_data)\n",
    "            loss = loss_fn(outputs.view(-1, num_labels), batch_labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.view(-1, num_labels), 1)\n",
    "            total_val += batch_labels.size(0)\n",
    "            correct_val += (predicted == batch_labels).sum().item()\n",
    "    val_accuracy = correct_val / total_val\n",
    "    average_val_loss = val_loss / len(val_data_loader)\n",
    "    print(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Implement early stopping\n",
    "    if early_stopper.early_stop(average_val_loss):\n",
    "        print(\"Early stopping triggered. No improvement in validation loss.\")\n",
    "        break  # Exit the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 300, 8]), torch.Size([32]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, batch_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 300, 8])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NER labels mapping\n",
    "\n",
    "\n",
    "# Convert NER tags to numerical labels\n",
    "train_df['NER Label'] = train_df['NEr tag'].map(ner_labels)\n",
    "validation_df['NER Label'] = validation_df['NEr tag'].map(ner_labels)\n",
    "\n",
    "# Tokenize and preprocess the data\n",
    "X_train, y_train = preprocess_data(train_df, w2v)\n",
    "X_validation, y_validation = preprocess_data(validation_df, w2v)\n",
    "\n",
    "# Define the NER model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=X_train.shape[0], output_dim=300, input_length=X_train.shape[1], weights=[X_train], trainable=False))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dense(8, activation='softmax'))  # 8 output classes (NER labels)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance using F1 score\n",
    "y_pred = model.predict(X_validation)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_true = np.argmax(y_validation, axis=-1)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"F1 Score on Validation Set: {f1}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Ensure date format datas etc are all in string parameters\n",
    "def list_of_words(df):\n",
    "    return [str(word) for word in df['Word'].to_list()]\n",
    "\n",
    "def create_embedding_matrix(word2vec_model, word_index):\n",
    "    embedding_dim = word2vec_model.vector_size\n",
    "    vocab_size = len(word_index) + 1  # Adding 1 to account for the reserved index 0\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        if word in word2vec_model:\n",
    "            embedding_matrix[i] = word2vec_model[word]\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "# Tokenize words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list_of_words(train_df))\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(word_index) + 1\n",
    "tag_types = train_df['NEr tag'].unique()\n",
    "\n",
    "# Create sequences for training, validation, and test data\n",
    "max_sequence_length = 100  # You can adjust this based on your data\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(list_of_words(train_df)), maxlen=max_sequence_length)\n",
    "X_val = pad_sequences(tokenizer.texts_to_sequences(list_of_words(validation_df)), maxlen=max_sequence_length)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(list_of_words(test_df)), maxlen=max_sequence_length)\n",
    "\n",
    "embedding_dim = 300  # Word2Vec embedding dimension\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length, trainable=False, weights=[create_embedding_matrix(w2v, word_index)]))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dense(len(tag_types), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def sentence_integrate(data):\n",
    "    agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                 s[\"NEr tag\"].values.tolist())]\n",
    "    return data.groupby('Sentence Number').apply(agg_func).tolist()\n",
    "  \n",
    "train_df_sentences = sentence_integrate(train_df)\n",
    "validation_df_sentences = sentence_integrate(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "count_of_sentence_lengths = defaultdict(int)\n",
    "for s in train_df_sentences:\n",
    "    count_of_sentence_lengths[len(s)]+=1\n",
    "\n",
    "plt.bar(count_of_sentence_lengths.keys(), count_of_sentence_lengths.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_mode_selection(df, sentences):\n",
    "        X = df[\"Word\"].tolist()\n",
    "        y = df[\"NEr tag\"].tolist()\n",
    "        \n",
    "        words = list(set(df[\"Word\"].values))\n",
    "        # words.append(\"ENDPAD\")\n",
    "        num_words = len(words)\n",
    "\n",
    "        tags = list(set(df[\"NEr tag\"].values))\n",
    "        num_tags = len(tags)\n",
    "\n",
    "        word2idx = {w: i for i, w in enumerate(X)}\n",
    "        tag2idx = {t: i for i, t in enumerate(y)}\n",
    "\n",
    "        X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "        X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=num_words)\n",
    "\n",
    "        y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "        y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_mode_selection(train_df, train_df_sentences)\n",
    "X_validation, y_validation = get_mode_selection(validation_df, validation_df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 50, 50)            1181150   \n",
      "                                                                 \n",
      " spatial_dropout1d_3 (Spatia  (None, 50, 50)           0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 50, 200)          120800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,301,950\n",
      "Trainable params: 1,301,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#split into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#build model\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import InputLayer, TimeDistributed, SpatialDropout1D, Bidirectional\n",
    "from tensorflow import keras\n",
    "\n",
    "max_len = 50\n",
    "words = list(set(train_df[\"Word\"].values))\n",
    "num_words = len(words)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(InputLayer((max_len)))\n",
    "model.add(Embedding(input_dim=num_words, output_dim=max_len, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.1))\n",
    "model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)))\n",
    "\n",
    "#model summary\n",
    "model.summary()\n",
    "\n",
    "#compile model\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define your model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_seq_length, weights=[embedding_matrix], trainable=False))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), batch_size=batch_size, epochs=epochs, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_7/embedding_5/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      sys.set_coroutine_origin_tracking_depth(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\woony\\AppData\\Local\\Temp\\ipykernel_26516\\1706387013.py\", line 6, in <module>\n      history = model.fit(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_7/embedding_5/embedding_lookup'\nindices[16,0] = 140952 is not in [0, 23623)\n\t [[{{node sequential_7/embedding_5/embedding_lookup}}]] [Op:__inference_train_function_21037]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[446], line 14\u001b[0m\n\u001b[0;32m      9\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [PlotLossesCallback(), chkpt, early_stopping,tensorboard_callback]\n\u001b[1;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#Apply TensorBoard to check the detailed structure and performance\u001b[39;00m\n\u001b[0;32m     26\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_7/embedding_5/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      sys.set_coroutine_origin_tracking_depth(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\woony\\AppData\\Local\\Temp\\ipykernel_26516\\1706387013.py\", line 6, in <module>\n      history = model.fit(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_7/embedding_5/embedding_lookup'\nindices[16,0] = 140952 is not in [0, 23623)\n\t [[{{node sequential_7/embedding_5/embedding_lookup}}]] [Op:__inference_train_function_21037]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "logdir=\"log/\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "chkpt = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=1, verbose=0, mode='max', baseline=None, restore_best_weights=False)\n",
    "\n",
    "callbacks = [PlotLossesCallback(), chkpt, early_stopping,tensorboard_callback]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    batch_size=32, \n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    "    \n",
    ")\n",
    "\n",
    "#Apply TensorBoard to check the detailed structure and performance\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 300)          5304300   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 128)          219648    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100, 8)            1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,524,980\n",
      "Trainable params: 220,680\n",
      "Non-trainable params: 5,304,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from your tag types to integer labels\n",
    "tag_to_label = {tag: idx for idx, tag in enumerate(tag_types)}\n",
    "\n",
    "# Convert tags to integer labels\n",
    "y_train = [tag_to_label[tag] for tag in train_df['NEr tag']]\n",
    "y_val = [tag_to_label[tag] for tag in validation_df['NEr tag']]\n",
    "y_test = [tag_to_label[tag] for tag in test_df['NEr tag']]\n",
    "\n",
    "# Convert integer labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=len(tag_types))\n",
    "y_val = to_categorical(y_val, num_classes=len(tag_types))\n",
    "y_test = to_categorical(y_test, num_classes=len(tag_types))\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(tag_types)\n",
    "\n",
    "# Convert integer labels to one-hot encoding for each word in the sequence\n",
    "y_train_onehot = [to_categorical(y, num_classes=num_classes) for y in y_train]\n",
    "y_val_onehot = [to_categorical(y, num_classes=num_classes) for y in y_val]\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "y_train_onehot = np.array(y_train_onehot)\n",
    "y_val_onehot = np.array(y_val_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 8, 8) and (None, 100, 8) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[364], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_onehot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileumshh6c8.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 8, 8) and (None, 100, 8) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot), epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 8) and (None, 100, 8) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[358], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileumshh6c8.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\woony\\anaconda3\\envs\\cz4045_env\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 8) and (None, 100, 8) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cz4045_env",
   "language": "python",
   "name": "cz4045_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
