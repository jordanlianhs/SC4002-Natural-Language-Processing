{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Sequence Tagging: NER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1 Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1.1 Download Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/43.6 kB 320.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.6/43.6 kB 709.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seqeval) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seqeval) (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16185 sha256=441067483e9e85f71c52b2bcfc4597a45fbb754df43aad7f41e18e005e30fa36\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\bc\\92\\f0\\243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from seqeval.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH  = 'Data/eng.train'\n",
    "DEVELOPMENT_PATH = 'Data/eng.testa'\n",
    "TEST_PATH = 'Data/eng.testb'\n",
    "OUTPUT_DIR = 'Data/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1.2 Download the pretrained word2vec embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "#Download the embeddings \"word2vec-google-news-300\"\n",
    "glove_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1.3 Query the vector of any word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the vecotr of any word by specifcying the word as the key\n",
    "#glove_vectors['beautiful']\n",
    "glove_vectors['computer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1 Finding most similar words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Com SCi\\SC 2002\\SC4002-Natural-Language-Processing\\main.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Com%20SCi/SC%202002/SC4002-Natural-Language-Processing/main.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Check if word is in vocab\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Com%20SCi/SC%202002/SC4002-Natural-Language-Processing/main.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m glove_vectors\u001b[39m.\u001b[39mkey_to_index:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Com%20SCi/SC%202002/SC4002-Natural-Language-Processing/main.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Com%20SCi/SC%202002/SC4002-Natural-Language-Processing/main.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Use most_similar to find word with the most similar cosines\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Com%20SCi/SC%202002/SC4002-Natural-Language-Processing/main.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# topn =1 only lists the most similar word\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Com%20SCi/SC%202002/SC4002-Natural-Language-Processing/main.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     similar_words \u001b[39m=\u001b[39m glove_vectors\u001b[39m.\u001b[39;49mmost_similar(word, topn\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)  \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Com%20SCi/SC%202002/SC4002-Natural-Language-Processing/main.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWords most similar to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mword\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Com%20SCi/SC%202002/SC4002-Natural-Language-Processing/main.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# Print the similarity scores\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:849\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[39mif\u001b[39;00m indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(topn, \u001b[39mint\u001b[39m):\n\u001b[0;32m    847\u001b[0m     \u001b[39mreturn\u001b[39;00m indexer\u001b[39m.\u001b[39mmost_similar(mean, topn)\n\u001b[1;32m--> 849\u001b[0m dists \u001b[39m=\u001b[39m dot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectors[clip_start:clip_end], mean) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorms[clip_start:clip_end]\n\u001b[0;32m    850\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m topn:\n\u001b[0;32m    851\u001b[0m     \u001b[39mreturn\u001b[39;00m dists\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word = \"student\"\n",
    "\n",
    "# Check if word is in vocab\n",
    "if word in glove_vectors.key_to_index:\n",
    "    \n",
    "    # Use most_similar to find word with the most similar cosines\n",
    "    # topn =1 only lists the most similar word\n",
    "    similar_words = glove_vectors.most_similar(word, topn=1)  \n",
    "    print(f\"Words most similar to '{word}':\")\n",
    "    \n",
    "    # Print the similarity scores\n",
    "    for similar_word, similarity_score in similar_words:\n",
    "        print(f\"{similar_word}: {similarity_score}\")\n",
    "else:\n",
    "    print(f\"'{word}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to 'Apple':\n",
      "Apple_AAPL: 0.7456986308097839\n"
     ]
    }
   ],
   "source": [
    "word = \"Apple\"\n",
    "\n",
    "# Check if word is in vocab\n",
    "if word in glove_vectors.key_to_index:\n",
    "    \n",
    "    # Use most_similar to find word with the most similar cosines\n",
    "    # topn=1 only lists the most similar word\n",
    "    similar_words = glove_vectors.most_similar(word, topn=1)  \n",
    "    print(f\"Words most similar to '{word}':\")\n",
    "    \n",
    "    # Print the similarity scores\n",
    "    for similar_word, similarity_score in similar_words:\n",
    "        print(f\"{similar_word}: {similarity_score}\")\n",
    "else:\n",
    "    print(f\"'{word}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to 'apple':\n",
      "apples: 0.720359742641449\n"
     ]
    }
   ],
   "source": [
    "word = \"apple\"\n",
    "\n",
    "# Check if word is in vocab\n",
    "if word in glove_vectors.key_to_index:\n",
    "    \n",
    "    # Use most_similar to find word with the most similar cosines\n",
    "    # topn =1 only lists the most similar word\n",
    "    similar_words = glove_vectors.most_similar(word, topn=1)  \n",
    "    print(f\"Words most similar to '{word}':\")\n",
    "    \n",
    "    # Print the similarity scores\n",
    "    for similar_word, similarity_score in similar_words:\n",
    "        print(f\"{similar_word}: {similarity_score}\")\n",
    "else:\n",
    "    print(f\"'{word}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 a) Size of training, development and test files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing files and converting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv(filepath,name):\n",
    "    OUTPUT_PATH = os.path.join(OUTPUT_DIR,name)\n",
    "    HEADERS = [\"sentence_number\",'word','tag']\n",
    "    sentence_number = 1\n",
    "    with open(OUTPUT_PATH,'w',newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile)\n",
    "                    csv_writer.writerow(HEADERS)\n",
    "    data =[]\n",
    "    with open(filepath, 'r') as file:\n",
    "    # Read the file line by line\n",
    "        for line in file:\n",
    "            # Check for blank lines\n",
    "            if line.strip() =='':\n",
    "                sentence_number+=1\n",
    "                with open(OUTPUT_PATH,'a',newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile)\n",
    "                    csv_writer.writerow([]) \n",
    "            else:\n",
    "                # Write sentence_number, word and its tag to csv\n",
    "                words = line.split()\n",
    "                data.append(sentence_number)\n",
    "                data.append(words[0])\n",
    "                data.append(words[-1])\n",
    "                with open(OUTPUT_PATH,'a',newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile)\n",
    "                    csv_writer.writerow(data) \n",
    "                data = []\n",
    "\n",
    "#Converting all data to csv                 \n",
    "convert_to_csv(TRAIN_PATH,'train.csv')\n",
    "convert_to_csv(DEVELOPMENT_PATH,'development.csv')\n",
    "convert_to_csv(TEST_PATH,'test.csv')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train file: 14987\n",
      "number of words : 23623\n",
      "tags : ['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Reading train.csv using pandas\n",
    "train_df = pd.read_csv(os.path.join(OUTPUT_DIR,'train.csv'))\n",
    "\n",
    "# Printing size, number of words and tags\n",
    "print(f\"Size of train file: {train_df['sentence_number'].iloc[-1]}\")\n",
    "print(f\"number of words : {len(train_df['word'].unique())}\")\n",
    "print(f\"tags : {sorted(train_df['tag'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Development File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train file: 3466\n",
      "number of words : 9966\n",
      "tags : ['B-MISC', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Reading development.csv using Pandas\n",
    "development_df = pd.read_csv(os.path.join(OUTPUT_DIR,'development.csv'))\n",
    "\n",
    "# Printing size, number of words and tags\n",
    "print(f\"Size of train file: {development_df['sentence_number'].iloc[-1]}\")\n",
    "print(f\"number of words : {len(development_df['word'].unique())}\")\n",
    "print(f\"tags : {sorted(development_df['tag'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train file: 3684\n",
      "number of words : 9489\n",
      "tags : ['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Reading test.csv using pandas\n",
    "test_df = pd.read_csv(os.path.join(OUTPUT_DIR,'test.csv'))\n",
    "\n",
    "\n",
    "# Printing size, number of words and tags\n",
    "print(f\"Size of train file: {test_df['sentence_number'].iloc[-1]}\")\n",
    "print(f\"number of words : {len(test_df['word'].unique())}\")\n",
    "print(f\"tags : {sorted(test_df['tag'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Q1b) choose an example sentence from the training set of CoNLL2003 that has at least two named entities with more than one word. Explain how to form complete named entities from the label for each word, and list all the named entities in this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1b(df):\n",
    "    while True:\n",
    "        # Keeps track of number of entities\n",
    "        count =0\n",
    "        \n",
    "        # Generate a random sentence number\n",
    "        rand = random.randint(1,df['sentence_number'].iloc[-1]+1)\n",
    "\n",
    "        # Filter df by sentence_number\n",
    "        mask = df['sentence_number'] == rand\n",
    "        rand_df = df[mask].reset_index()\n",
    "\n",
    "        # Check is to ensure we do not double count consecutive word with same tag\n",
    "        check = None\n",
    "\n",
    "        # Check through dataframe and count number of entities\n",
    "        for x in range(len(rand_df['tag'])):\n",
    "            if x < len(rand_df['tag'])-1:\n",
    "                \n",
    "                # Check current tag !='O'\n",
    "                if rand_df['tag'].iloc[x]!='O':\n",
    "                    \n",
    "                    # Check if current tag starts with 'B-'\n",
    "                    if rand_df['tag'].iloc[x].startswith('B-'):\n",
    "                        \n",
    "                        # Strip current tag of 'B-' and next tag of 'I-'\n",
    "                        if rand_df['tag'].iloc[x].strip('B-') == rand_df['tag'].iloc[x+1].strip('I-'):\n",
    "                            \n",
    "                             # updating check if tags are the same \n",
    "                            if check == rand_df['tag'].iloc[x-1]:\n",
    "                                check = rand_df['tag'].iloc[x]\n",
    "\n",
    "                            # Incrementing count and updating check\n",
    "                            else:\n",
    "                                count+=1\n",
    "                                check = rand_df['tag'].iloc[x]\n",
    "                \n",
    "                \n",
    "                    #Check if current tag == next tag\n",
    "                    elif rand_df['tag'].iloc[x+1] == rand_df['tag'].iloc[x]:\n",
    "\n",
    "                        # updating check if tags are the same \n",
    "                        if check == rand_df['tag'].iloc[x-1]:\n",
    "                            check = rand_df['tag'].iloc[x]\n",
    "\n",
    "                        # Incrementing count and updating check\n",
    "                        else:\n",
    "                            count+=1\n",
    "                            check = rand_df['tag'].iloc[x]\n",
    "\n",
    "                # Reinitialise check to None once 'O' detected to ensure other different named entities of same tag as previous is counted.\n",
    "                elif rand_df['tag'].iloc[x]=='O':\n",
    "                    check = None\n",
    "\n",
    "                # Return once count >=2\n",
    "                if count >=2:\n",
    "                    return rand_df          \n",
    "                \n",
    "                \n",
    "\n",
    "q1b_df = q1b(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: South African provincial side Boland said on Thursday they had signed Leicestershire fast bowler David Millns on a one year contract . \n",
      "tag: I-MISC I-MISC O O I-ORG O O O O O O I-ORG O O I-PER I-PER O O O O O O \n",
      "sentence with tag: South/I-MISC African/I-MISC provincial/O side/O Boland/I-ORG said/O on/O Thursday/O they/O had/O signed/O Leicestershire/I-ORG fast/O bowler/O David/I-PER Millns/I-PER on/O a/O one/O year/O contract/O ./O \n"
     ]
    }
   ],
   "source": [
    "def process(df):\n",
    "    sentence = ''\n",
    "    tag = ''\n",
    "    sen_and_tag = ''\n",
    "    for x in range (len(df['word'])):\n",
    "        sentence += str(df['word'].iloc[x])\n",
    "        sentence+= ' '\n",
    "        tag += str(df['tag'].iloc[x])\n",
    "        tag+=' '\n",
    "        sen_and_tag +=str(df['word'].iloc[x])\n",
    "        sen_and_tag +='/'\n",
    "        sen_and_tag += str(df['tag'].iloc[x])\n",
    "        sen_and_tag += ' '\n",
    "    print(f\"sentence: {sentence}\")\n",
    "    print(f\"tag: {tag}\")\n",
    "    print(f\"sentence with tag: {sen_and_tag}\")\n",
    "\n",
    "process(q1b_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(df):\n",
    "\n",
    "    # Keeps track of number of entities\n",
    "    count =0\n",
    "    \n",
    "\n",
    "    # Check is to ensure we do not double count consecutive word with same tag\n",
    "    check = None\n",
    "\n",
    "    # Check through dataframe and count number of entities\n",
    "    for x in range(len(df['tag'])):\n",
    "        if x < len(df['tag'])-1:\n",
    "            # Check tag !='O', next tag is same as current tag \n",
    "            if df['tag'].iloc[x]!='O':\n",
    "                if df['tag'].iloc[x].startswith('B-'):\n",
    "                    if df['tag'].iloc[x].strip('B-') == df['tag'].iloc[x+1].strip('I-'):\n",
    "                            # updating check if tags are the same \n",
    "                        if check == df['tag'].iloc[x-1]:\n",
    "                            check = df['tag'].iloc[x]\n",
    "\n",
    "                        # Incrementing count and updating check\n",
    "                        else:\n",
    "                            count+=1\n",
    "                            check = df['tag'].iloc[x]\n",
    "            \n",
    "            \n",
    "            \n",
    "                elif df['tag'].iloc[x+1] == df['tag'].iloc[x]:\n",
    "\n",
    "                    # updating check if tags are the same \n",
    "                    if check == df['tag'].iloc[x-1]:\n",
    "                        check = df['tag'].iloc[x]\n",
    "\n",
    "                    # Incrementing count and updating check\n",
    "                    else:\n",
    "                        count+=1\n",
    "                        check = df['tag'].iloc[x]\n",
    "\n",
    "            # Reinitialise check to None once 'O' detected to ensure other different named entities of same tag as previous is counted.\n",
    "            elif df['tag'].iloc[x]=='O':\n",
    "                check = None\n",
    "\n",
    "           \n",
    "    return count\n",
    "  \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "sentence: Australian Davis Cup captain John Newcombe on Thursday signalled his possible resignation if his team loses an away tie against Croatia next month . \n",
      "tag: I-MISC B-MISC I-MISC O I-PER I-PER O O O O O O O O O O O O O O I-LOC O O O \n",
      "sentence with tag: Australian/I-MISC Davis/B-MISC Cup/I-MISC captain/O John/I-PER Newcombe/I-PER on/O Thursday/O signalled/O his/O possible/O resignation/O if/O his/O team/O loses/O an/O away/O tie/O against/O Croatia/I-LOC next/O month/O ./O \n"
     ]
    }
   ],
   "source": [
    "mask = train_df['sentence_number'] == 679\n",
    "df = train_df[mask].reset_index()\n",
    "print(check(df))\n",
    "process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of name entities: ['South African ', 'Boland ', 'Leicestershire ', 'David Millns ']\n",
      "list of name entities with tags {'South African ': 'I-MISC', 'Boland ': 'I-ORG', 'Leicestershire ': 'I-ORG', 'David Millns ': 'I-PER'}\n"
     ]
    }
   ],
   "source": [
    "def list_named_entities(df):\n",
    "    entity =''\n",
    "    l =[]\n",
    "    t = []\n",
    "    for x in range(len(df['word'])):\n",
    "        if df['tag'].iloc[x]!='O':\n",
    "            entity+=str(df['word'].iloc[x])\n",
    "            entity+=' '\n",
    "        else:\n",
    "            if (entity!=''):\n",
    "                l.append(entity)\n",
    "                t.append(str(df['tag'].iloc[x-1]))\n",
    "                entity = ''\n",
    "    d = {k: v for k, v in zip(l,t)} \n",
    "    return l,d\n",
    "\n",
    "l,d= list_named_entities(q1b_df)\n",
    "print(f\"list of name entities: {l}\")\n",
    "print(f\"list of name entities with tags {d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
