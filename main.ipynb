{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Sequence Tagging: NER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1 Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1.1 Download Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/af/7b/d170f9c8306c7673f57ca4f442e326d36e20299725edc5d0af36a3e3b041/pandas-2.1.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pandas-2.1.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dingangoh/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/dingangoh/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.1.1-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.1.1 pytz-2023.3.post1 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH  = 'Data/eng.train'\n",
    "DEVELOPMENT_PATH = 'Data/eng.testa'\n",
    "TEST_PATH = 'Data/eng.testb'\n",
    "OUTPUT_DIR = 'Data/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1.2 Download the pretrained word2vec embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "#Download the embeddings \"word2vec-google-news-300\"\n",
    "glove_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1.3 Query the vector of any word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the vecotr of any word by specifcying the word as the key\n",
    "#glove_vectors['beautiful']\n",
    "glove_vectors['computer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1 Finding most similar words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to 'student':\n",
      "students: 0.7294867038726807\n"
     ]
    }
   ],
   "source": [
    "word = \"student\"\n",
    "\n",
    "# Check if word is in vocab\n",
    "if word in glove_vectors.key_to_index:\n",
    "    \n",
    "    # Use most_similar to find word with the most similar cosines\n",
    "    # topn =1 only lists the most similar word\n",
    "    similar_words = glove_vectors.most_similar(word, topn=1)  \n",
    "    print(f\"Words most similar to '{word}':\")\n",
    "    \n",
    "    # Print the similarity scores\n",
    "    for similar_word, similarity_score in similar_words:\n",
    "        print(f\"{similar_word}: {similarity_score}\")\n",
    "else:\n",
    "    print(f\"'{word}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to 'Apple':\n",
      "Apple_AAPL: 0.7456986308097839\n"
     ]
    }
   ],
   "source": [
    "word = \"Apple\"\n",
    "\n",
    "# Check if word is in vocab\n",
    "if word in glove_vectors.key_to_index:\n",
    "    \n",
    "    # Use most_similar to find word with the most similar cosines\n",
    "    # topn=1 only lists the most similar word\n",
    "    similar_words = glove_vectors.most_similar(word, topn=1)  \n",
    "    print(f\"Words most similar to '{word}':\")\n",
    "    \n",
    "    # Print the similarity scores\n",
    "    for similar_word, similarity_score in similar_words:\n",
    "        print(f\"{similar_word}: {similarity_score}\")\n",
    "else:\n",
    "    print(f\"'{word}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to 'apple':\n",
      "apples: 0.720359742641449\n"
     ]
    }
   ],
   "source": [
    "word = \"apple\"\n",
    "\n",
    "# Check if word is in vocab\n",
    "if word in glove_vectors.key_to_index:\n",
    "    \n",
    "    # Use most_similar to find word with the most similar cosines\n",
    "    # topn =1 only lists the most similar word\n",
    "    similar_words = glove_vectors.most_similar(word, topn=1)  \n",
    "    print(f\"Words most similar to '{word}':\")\n",
    "    \n",
    "    # Print the similarity scores\n",
    "    for similar_word, similarity_score in similar_words:\n",
    "        print(f\"{similar_word}: {similarity_score}\")\n",
    "else:\n",
    "    print(f\"'{word}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 a) Size of training, development and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv(filepath,name):\n",
    "    OUTPUT_PATH = os.path.join(OUTPUT_DIR,name)\n",
    "    HEADERS = [\"sentence_number\",'word','tag']\n",
    "    sentence_number = 1\n",
    "    with open(OUTPUT_PATH,'w',newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile)\n",
    "                    csv_writer.writerow(HEADERS)\n",
    "    data =[]\n",
    "    with open(filepath, 'r') as file:\n",
    "    # Read the file line by line\n",
    "        for line in file:\n",
    "            if line.strip() =='':\n",
    "                sentence_number+=1\n",
    "                with open(OUTPUT_PATH,'a',newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile)\n",
    "                    csv_writer.writerow([]) \n",
    "            else:\n",
    "                words = line.split()\n",
    "                data.append(sentence_number)\n",
    "                data.append(words[0])\n",
    "                data.append(words[-1])\n",
    "                with open(OUTPUT_PATH,'a',newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile)\n",
    "                    csv_writer.writerow(data) \n",
    "                data = []\n",
    "                \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_csv(filepath,name):\n",
    "#     OUTPUT_PATH = os.path.join(OUTPUT_DIR,name)\n",
    "#     print(OUTPUT_PATH)\n",
    "#     sentence= []\n",
    "#     tags =[]\n",
    "#     with open(filepath, 'r') as file:\n",
    "#     # Read the file line by line\n",
    "#         for line in file:\n",
    "#             if line.strip() =='':\n",
    "#                 with open(OUTPUT_PATH,'a',newline='') as csvfile:\n",
    "#                     csv_writer = csv.writer(csvfile)\n",
    "#                     csv_writer.writerow(sentence)\n",
    "#                     csv_writer.writerow(tags)\n",
    "#                     csv_writer.writerow([]) \n",
    "#                 sentence = []\n",
    "#                 tags = []\n",
    "#             else:\n",
    "#                 words = line.split()\n",
    "#                 sentence.append(words[0])\n",
    "#                 tags.append(words[-1])\n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_csv(TRAIN_PATH,'train.csv')\n",
    "convert_to_csv(DEVELOPMENT_PATH,'development.csv')\n",
    "convert_to_csv(TEST_PATH,'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train file: 14987\n",
      "number of words : <bound method IndexOpsMixin.nunique of 0                 EU\n",
      "1            rejects\n",
      "2             German\n",
      "3               call\n",
      "4                 to\n",
      "             ...    \n",
      "204562       Swansea\n",
      "204563             1\n",
      "204564       Lincoln\n",
      "204565             2\n",
      "204566    -DOCSTART-\n",
      "Name: word, Length: 204567, dtype: object>\n",
      "tags : <bound method Series.unique of 0          I-ORG\n",
      "1              O\n",
      "2         I-MISC\n",
      "3              O\n",
      "4              O\n",
      "           ...  \n",
      "204562     I-ORG\n",
      "204563         O\n",
      "204564     I-ORG\n",
      "204565         O\n",
      "204566         O\n",
      "Name: tag, Length: 204567, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(OUTPUT_DIR,'train.csv'))\n",
    "train_df.head()\n",
    "print(f\"Size of train file: {train_df['sentence_number'].iloc[-1]}\")\n",
    "print(f\"number of words : {train_df['word'].nunique}\")\n",
    "print(f\"tags : {train_df['tag'].unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 14041\n"
     ]
    }
   ],
   "source": [
    "# sentence_count=0\n",
    "# #Flag for skipping count\n",
    "# skip =False  \n",
    "\n",
    "# with open('Data/eng.train', 'r') as file:\n",
    "#     # Read the file line by line\n",
    "#     for line in file:\n",
    "        \n",
    "#         # Check for DOCSTART string\n",
    "#         if line.strip() == '-DOCSTART- -X- O O':\n",
    "            \n",
    "#             # Skip flag is set to True if line ==  '-DOCSTART- -X- O O'\n",
    "#             skip=True\n",
    "        \n",
    "#         # If it's a blank line and we are not skipping, increment the sentence count    \n",
    "#         elif line.strip() == '' :\n",
    "#             if not skip:\n",
    "#                 sentence_count += 1\n",
    "            \n",
    "#             # Resetting skip flag    \n",
    "#             skip =False\n",
    "\n",
    "# # Print the total number of sentences\n",
    "# print(f\"Total number of sentences: {sentence_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Development File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train file: 3466\n"
     ]
    }
   ],
   "source": [
    "development_df = pd.read_csv(os.path.join(OUTPUT_DIR,'development.csv'))\n",
    "development_df.head()\n",
    "print(f\"Size of train file: {development_df['sentence_number'].iloc[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 3250\n"
     ]
    }
   ],
   "source": [
    "# sentence_count=0\n",
    "# #Flag for skipping count\n",
    "# skip =False  \n",
    "\n",
    "# with open('Data/eng.testa', 'r') as file:\n",
    "#     # Read the file line by line\n",
    "#     for line in file:\n",
    "        \n",
    "#         # Check for DOCSTART string\n",
    "#         if line.strip() == '-DOCSTART- -X- O O':\n",
    "            \n",
    "#             # Skip flag is set to True if line ==  '-DOCSTART- -X- O O'\n",
    "#             skip=True\n",
    "        \n",
    "#         # If it's a blank line and we are not skipping, increment the sentence count    \n",
    "#         elif line.strip() == '' :\n",
    "#             if not skip:\n",
    "#                 sentence_count += 1\n",
    "            \n",
    "#             # Resetting skip flag    \n",
    "#             skip =False\n",
    "\n",
    "# # Print the total number of sentences\n",
    "# print(f\"Total number of sentences: {sentence_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train file: 3684\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(OUTPUT_DIR,'test.csv'))\n",
    "test_df.head()\n",
    "print(f\"Size of train file: {test_df['sentence_number'].iloc[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 3683\n"
     ]
    }
   ],
   "source": [
    "# sentence_count=0\n",
    "# #Flag for skipping count\n",
    "# skip =False  \n",
    "\n",
    "# with open('Data/eng.testb', 'r') as file:\n",
    "#     # Read the file line by line\n",
    "#     for line in file:\n",
    "        \n",
    "#         # Check for DOCSTART string\n",
    "#         if line.strip() == '-DOCSTART- -X- O O':\n",
    "            \n",
    "#             # Skip flag is set to True if line ==  '-DOCSTART- -X- O O'\n",
    "#             skip=True\n",
    "        \n",
    "#         # If it's a blank line and we are not skipping, increment the sentence count    \n",
    "#         elif line.strip() == '' :\n",
    "#             if not skip:\n",
    "#                 sentence_count += 1\n",
    "            \n",
    "#             # Resetting skip flag    \n",
    "#             skip =False\n",
    "\n",
    "# # Print the total number of sentences\n",
    "# print(f\"Total number of sentences: {sentence_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
